{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_CNN_Full.ipynb","provenance":[{"file_id":"1V8Fy_X5dyxL4Hv0Oyf4wZH_BuQ5QlbZx","timestamp":1631707858890},{"file_id":"1CSt8n4xXstRxN7ixlBeyXgWLbXqVqmiY","timestamp":1568635885203}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"OqMgNDCg8SuY"},"source":["# MNIST Convolutional Neural Network Classifier\n","We compute a convolutional filter based approach to classify the MNIST database. This script will house the entire pipeline upon completion.\n","\n","First, import the relevant libraries and functions."]},{"cell_type":"code","metadata":{"id":"eRW0URxC8OBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636259723155,"user_tz":-600,"elapsed":2347,"user":{"displayName":"Wakayama Hideki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX8nPmXxUwee3ETuvhR0wO18p4u7HNRL2KAZ97=s64","userId":"16567349205826503190"}},"outputId":"2f02675f-57e9-4c5a-8a01-e8773a8606c4"},"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","\n","print(tf.keras.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"6EZ27ZD58-IZ"},"source":["Next define the parameters to use for the algorithm"]},{"cell_type":"code","metadata":{"id":"xeCAfd4U836D","executionInfo":{"status":"ok","timestamp":1636259723156,"user_tz":-600,"elapsed":9,"user":{"displayName":"Wakayama Hideki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX8nPmXxUwee3ETuvhR0wO18p4u7HNRL2KAZ97=s64","userId":"16567349205826503190"}}},"source":["depth = 32 #how much encoding to apply\n","n = 28 #image dim\n","batch_size = 256\n","epochs = 5\n","categories = 10"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZk1y-i59I3L"},"source":["Next we create the network. To be done in class"]},{"cell_type":"code","metadata":{"id":"dc_X3APd9IND","executionInfo":{"status":"ok","timestamp":1636259726501,"user_tz":-600,"elapsed":3352,"user":{"displayName":"Wakayama Hideki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX8nPmXxUwee3ETuvhR0wO18p4u7HNRL2KAZ97=s64","userId":"16567349205826503190"}}},"source":["#create the network\n","inputs = Input(shape=(n,n,1))\n","net1 = Conv2D(depth, (3,3), padding=\"same\", activation=\"relu\")(inputs)\n","pool1 = MaxPooling2D(pool_size=(2,2))(net1)\n","net2 = Conv2D(depth*2, (3,3), padding=\"same\", activation=\"relu\")(pool1)\n","pool2 = MaxPooling2D(pool_size=(2,2))(net2)\n","net3 = Conv2D(depth*4, (3,3), padding=\"same\", activation=\"relu\")(pool2)\n","pool3 = MaxPooling2D(pool_size=(2,2))(net3)\n","flat = Flatten()(pool3)\n","net4 = Dense(128, activation=\"relu\")(flat)\n","output = Dense(categories, activation=\"softmax\")(net4)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"krty1WFD9QQY"},"source":["Create the model from the network and maps inputs to output. We use the categorical cross entropy which is designed to handle multiple labels. However, to use this we need to one-hot encode the labels later."]},{"cell_type":"code","metadata":{"id":"6Qc57voh9PeB","executionInfo":{"status":"ok","timestamp":1636259726502,"user_tz":-600,"elapsed":12,"user":{"displayName":"Wakayama Hideki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX8nPmXxUwee3ETuvhR0wO18p4u7HNRL2KAZ97=s64","userId":"16567349205826503190"}}},"source":["#map an input to its reconstruction to create model\n","model = Model(inputs, output)\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vgEJ4oo99mGu"},"source":["Now that the model is ready, it its data. Load and preprocess the data."]},{"cell_type":"code","metadata":{"id":"ql-8-8v09xrv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636259727045,"user_tz":-600,"elapsed":552,"user":{"displayName":"Wakayama Hideki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX8nPmXxUwee3ETuvhR0wO18p4u7HNRL2KAZ97=s64","userId":"16567349205826503190"}},"outputId":"bdd40597-7fca-4d35-ee7a-114ffd823745"},"source":["#load the data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","#add extra dimension for conv2d\n","x_train = x_train[:,:,:,np.newaxis]\n","x_test = x_test[:,:,:,np.newaxis]\n","#categorical one hot\n","y_train_cat = to_categorical(y_train, categories)\n","y_test_cat = to_categorical(y_test, categories)\n","print(x_train.shape)\n","print(x_test.shape)\n","print(y_train_cat.shape)\n","print(y_test_cat.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","(60000, 28, 28, 1)\n","(10000, 28, 28, 1)\n","(60000, 10)\n","(10000, 10)\n"]}]},{"cell_type":"markdown","metadata":{"id":"dIeAoKFN-BIn"},"source":["Fit the data to the model that was created. We use the one-hot encoded labels and the testing test as the validation test (not good practice) to see accuracy"]},{"cell_type":"code","metadata":{"id":"95oS_nEe97jA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"135c3c21-a4cf-407b-f883-09de3c49af4f"},"source":["model.fit(x_train, y_train_cat,\n","                epochs=epochs,\n","                batch_size=batch_size,\n","                shuffle=True,\n","                validation_data=(x_test, y_test_cat))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]}]},{"cell_type":"markdown","metadata":{"id":"qNzXz4Yc-QF5"},"source":["Predict the labels of the test set by using the trained model"]},{"cell_type":"code","metadata":{"id":"bvXmgDWs-UpO"},"source":["# classify the digits using the trained model\n","# note that we take them from the *test* set\n","predictions = model.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sTdEA0Gq-aGK"},"source":["Now evaluate the performance just as we've done with our RF method"]},{"cell_type":"code","metadata":{"id":"9NsmjCsd-hrd"},"source":["#reverse one-hot encoding\n","predictions = np.argmax(predictions, axis=1)\n","print(predictions)\n","\n","#print performance to compare with previous RF versions\n","from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIf0z08Y_qjf"},"source":[""],"execution_count":null,"outputs":[]}]}